{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap Tutorial\n",
    "\n",
    "This notebook contains a tutorial on how to use the bootstrap functionality provided by estimagic. In this example, we will work with the \"exercise\" example dataset taken from the seaborn library.\n",
    "\n",
    "The working example will be a linear regression to investigate the effects of exercise time on pulse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  id     diet  pulse  time  kind  constant\n",
      "0           0   1  low fat     85     1  rest         1\n",
      "1           1   1  low fat     85    15  rest         1\n",
      "2           2   1  low fat     88    30  rest         1\n",
      "3           3   2  low fat     90     1  rest         1\n",
      "4           4   2  low fat     92    15  rest         1\n"
     ]
    }
   ],
   "source": [
    "df = sns.load_dataset(\"exercise\")\n",
    "\n",
    "dict = {\"1 min\": 1, \"15 min\": 15, \"30 min\": 30}\n",
    "\n",
    "df = df.replace({\"time\": dict})\n",
    "df[\"constant\"] = 1\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, there are two ways to use bootstrap functionality in estimagic. We can either use the main bootstrap() function, which will draw bootstrap samples, compute estimates, as well as compute standard errors and confidence intervals of these estimates at the same time. Or we can use the fact that all of the code is separated, and go through all of this step by step. \n",
    "\n",
    "In either way, the first thing that is required from the user is to specify a wrapping function that calculates the statistic of interest, and only takes the data on which to compute the statistic as an input. In our case, we want to regress \"pulse\" on \"time\" and a constant, and the function looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_fit(data):\n",
    "    \n",
    "    y = data[\"pulse\"]\n",
    "    x = data[[\"constant\", \"time\"]]\n",
    "    \n",
    "    params = pd.Series(\n",
    "        sm.OLS(y, x).fit().params, index=[\"constant\", \"time\"]\n",
    "    )\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By returning a pd.Series with the coefficient names as index, we make sure we will eventually get a nice and readable output table. This is however not necessary. We could also simply return the parameter vector, in which case we would simply have to keep in mind the meaning of each parameter by ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Easy Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining our function of interest, we can make use of estimagic's bootstrap functionality using one simple function call of the bootstrap() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               mean       std   lower_ci   upper_ci\n",
      "constant  93.800212  1.444054  91.092999  96.653470\n",
      "time       0.384128  0.123372   0.142345   0.644022\n"
     ]
    }
   ],
   "source": [
    "from estimagic.inference.bootstrap import bootstrap\n",
    "\n",
    "results_without_cluster = bootstrap(data=df, f=ols_fit)\n",
    "\n",
    "print(results_without_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function call represents the minimum that a user has to specify, making full use of the default options, such as drawing a 1000 bootstrap draws, using the \"percentile\" bootstrap confidence interval, not making use of parallelization, etc.\n",
    "\n",
    "If we would for example want to make 10000 draws, while parallelizing on 4 threads and using a \"bca\" type confidence interval, we would simply call the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               mean       std   lower_ci   upper_ci\n",
      "constant  93.756518  1.512834  91.850845  97.373046\n",
      "time       0.387780  0.124949   0.126304   0.556214\n"
     ]
    }
   ],
   "source": [
    "results_without_cluster2 = bootstrap(data=df, f=ols_fit, ndraws=10000, ci_method=\"bca\", num_threads=4)\n",
    "\n",
    "print(results_without_cluster2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare our estimates to simply running a full sample OLS estimation, and see that they are (naturally) quite similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>pulse</td>      <th>  R-squared:         </th> <td>   0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 28 Feb 2020</td> <th>  Prob (F-statistic):</th>  <td>0.00291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:39:55</td>     <th>  Log-Likelihood:    </th> <td> -365.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>   735.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    88</td>      <th>  BIC:               </th> <td>   740.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>constant</th> <td>   93.7611</td> <td>    2.450</td> <td>   38.275</td> <td> 0.000</td> <td>   88.893</td> <td>   98.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time</th>     <td>    0.3873</td> <td>    0.126</td> <td>    3.063</td> <td> 0.003</td> <td>    0.136</td> <td>    0.639</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>20.828</td> <th>  Durbin-Watson:     </th> <td>   0.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  26.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.173</td> <th>  Prob(JB):          </th> <td>1.93e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.231</td> <th>  Cond. No.          </th> <td>    31.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  pulse   R-squared:                       0.096\n",
       "Model:                            OLS   Adj. R-squared:                  0.086\n",
       "Method:                 Least Squares   F-statistic:                     9.383\n",
       "Date:                Fri, 28 Feb 2020   Prob (F-statistic):            0.00291\n",
       "Time:                        17:39:55   Log-Likelihood:                -365.51\n",
       "No. Observations:                  90   AIC:                             735.0\n",
       "Df Residuals:                      88   BIC:                             740.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "constant      93.7611      2.450     38.275      0.000      88.893      98.629\n",
       "time           0.3873      0.126      3.063      0.003       0.136       0.639\n",
       "==============================================================================\n",
       "Omnibus:                       20.828   Durbin-Watson:                   0.827\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.313\n",
       "Skew:                           1.173   Prob(JB):                     1.93e-06\n",
       "Kurtosis:                       4.231   Cond. No.                         31.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"pulse\"]\n",
    "x = df[[\"constant\", \"time\"]]\n",
    "\n",
    "regular_ols = sm.OLS(y, x).fit()\n",
    "\n",
    "regular_ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimagic implements two different types of bootstrap. In the standard bootstrap that we called in the two examples above, observations from the original dataset are drawn uniformly with replacement in order to create the different bootstrap samples.\n",
    "\n",
    "In the cluster robust variant of the bootstrap, the original dataset is divided into clusters according to the values of some user-specified variable, and then clusters are drawn uniformly with replacement in order to create the different bootstrap samples. \n",
    "\n",
    "In order to use the cluster robust boostrap, we simply specify which variable to cluster by. In the example we are working with, it seems sensible to cluster on individuals, i.e. on the column \"id\" of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               mean       std   lower_ci   upper_ci\n",
      "constant  93.752154  1.165025  91.546191  96.048796\n",
      "time       0.387964  0.103310   0.189072   0.598999\n"
     ]
    }
   ],
   "source": [
    "results_with_cluster = bootstrap(data=df, f=ols_fit, cluster_by=\"id\")\n",
    "\n",
    "print(results_with_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the estimated standard errors are indeed of a smaller magnitude when we use the cluster robust bootstrap, which is in line with the fact that standard errors are usually overestimated if we don't cluster when we should.\n",
    "\n",
    "Finally, we can compare the results to full sample regressions using the statsmodels regression function and see that the cluster robust bootstrap gives standard error estimates very close to the cluster robust regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>pulse</td>      <th>  R-squared:         </th> <td>   0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 28 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>0.000879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:39:58</td>     <th>  Log-Likelihood:    </th> <td> -365.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>   735.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    88</td>      <th>  BIC:               </th> <td>   740.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>cluster</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>constant</th> <td>   93.7611</td> <td>    1.205</td> <td>   77.837</td> <td> 0.000</td> <td>   91.400</td> <td>   96.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time</th>     <td>    0.3873</td> <td>    0.104</td> <td>    3.708</td> <td> 0.000</td> <td>    0.183</td> <td>    0.592</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>20.828</td> <th>  Durbin-Watson:     </th> <td>   0.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  26.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.173</td> <th>  Prob(JB):          </th> <td>1.93e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.231</td> <th>  Cond. No.          </th> <td>    31.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors are robust to cluster correlation (cluster)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  pulse   R-squared:                       0.096\n",
       "Model:                            OLS   Adj. R-squared:                  0.086\n",
       "Method:                 Least Squares   F-statistic:                     13.75\n",
       "Date:                Fri, 28 Feb 2020   Prob (F-statistic):           0.000879\n",
       "Time:                        17:39:58   Log-Likelihood:                -365.51\n",
       "No. Observations:                  90   AIC:                             735.0\n",
       "Df Residuals:                      88   BIC:                             740.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:              cluster                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "constant      93.7611      1.205     77.837      0.000      91.400      96.122\n",
       "time           0.3873      0.104      3.708      0.000       0.183       0.592\n",
       "==============================================================================\n",
       "Omnibus:                       20.828   Durbin-Watson:                   0.827\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.313\n",
       "Skew:                           1.173   Prob(JB):                     1.93e-06\n",
       "Kurtosis:                       4.231   Cond. No.                         31.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors are robust to cluster correlation (cluster)\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_robust_ols = sm.OLS(y, x).fit(\n",
    "        cov_type=\"cluster\", cov_kwds={\"groups\": df[\"id\"]}\n",
    "    )\n",
    "\n",
    "cluster_robust_ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The More Sophisticated Way\n",
    "\n",
    "In some analyses, we might be interested in not simply calculating one statistic of our sample, but indeed calculating several statistics of our sample one after another. Here I want to show how this can be done with bootstrap in estimagic.\n",
    "\n",
    "In a first step, we should fix seeds in order to make sure that the samples we base our estimates on are the same for each separate statistic. The seeds returned are simply an np.array of ndraws valid random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 323501399  588426255 1045046778 ... 1356650334 1868719583 1991488640]\n"
     ]
    }
   ],
   "source": [
    "from estimagic.inference.bootstrap_samples import get_seeds\n",
    "\n",
    "my_seeds = get_seeds(2000)\n",
    "\n",
    "print(my_seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can then go on to call the bootstrap function for different statistics, e.g. the above defined function and also a simple correlation coefficient of \"pulse\" and \"time\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(data):\n",
    "    \n",
    "    return pd.Series(data[\"pulse\"].corr(data[\"time\"]), index=[\"corr(pulse, time)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               mean       std   lower_ci   upper_ci\n",
      "constant  93.818926  1.527447  90.970883  96.963398\n",
      "time       0.386825  0.122389   0.161589   0.636060\n"
     ]
    }
   ],
   "source": [
    "results_ols = bootstrap(data=df, f=ols_fit, seeds=my_seeds)\n",
    "print(results_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       mean       std  lower_ci  upper_ci\n",
      "corr(pulse, time)  0.307829  0.081068  0.148877  0.467313\n"
     ]
    }
   ],
   "source": [
    "results_corr = bootstrap(data=df, f=corr, seeds=my_seeds)\n",
    "print(results_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Complete Separation of Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There might of course also be situations where we simply want to return the collection of bootstrap estimates and not directly get the very streamlined results table. The following example makes use of the complete separation of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_seeds = get_seeds(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use get_bootstrap_estimates() to get the pd.DataFrame containing all of the different bootstrap estimates for f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    constant      time\n",
      "0  93.782043  0.515684\n",
      "1  93.420674  0.403365\n",
      "2  93.422063  0.354121\n",
      "3  97.334865  0.148656\n",
      "4  91.635526  0.440604\n"
     ]
    }
   ],
   "source": [
    "from estimagic.inference.bootstrap_estimates import get_bootstrap_estimates\n",
    "\n",
    "my_estimates = get_bootstrap_estimates(data=df, f=ols_fit, seeds=more_seeds)\n",
    "\n",
    "print(my_estimates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute confidence intervals using estimates as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           lower_ci   upper_ci\n",
      "constant  91.328959  96.398915\n",
      "time       0.197747   0.619950\n"
     ]
    }
   ],
   "source": [
    "from estimagic.inference.bootstrap_ci import compute_ci\n",
    "\n",
    "confidence_intervals = compute_ci(data=df, f=ols_fit, estimates=my_estimates, ci_method=\"bc\")\n",
    "\n",
    "print(confidence_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can compute the whole results table using specific estimates as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               mean       std   lower_ci   upper_ci\n",
      "constant  93.754326  1.552568  90.615657  96.795346\n",
      "time       0.389216  0.127902   0.116775   0.614301\n"
     ]
    }
   ],
   "source": [
    "from estimagic.inference.bootstrap import get_results_table\n",
    "\n",
    "my_results = get_results_table(data=df, f=ols_fit, estimates=my_estimates, ci_method=\"t\")\n",
    "\n",
    "print(my_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that it is also possible to return the list of bootstrap samples using the get_bootstrap_samples() function. However, this can be very memory inefficient and is not recommended unless definitely needed. This function returns a list of ndraws bootstrap samples obtained from drawing from the original sample with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "    Unnamed: 0  id     diet  pulse  time     kind  constant\n",
      "57          57  20   no fat    102     1  walking         1\n",
      "32          32  11  low fat     84    30  walking         1\n",
      "0            0   1  low fat     85     1     rest         1\n",
      "66          66  23  low fat     98     1  running         1\n",
      "18          18   7   no fat     87     1     rest         1\n"
     ]
    }
   ],
   "source": [
    "from estimagic.inference.bootstrap_samples import get_bootstrap_samples\n",
    "\n",
    "my_samples = get_bootstrap_samples(data=df, seeds=my_seeds)\n",
    "\n",
    "print(type(my_samples))\n",
    "\n",
    "print(my_samples[4].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
