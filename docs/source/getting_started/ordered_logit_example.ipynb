{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordered Logit Example\n",
    "\n",
    "Let's suppose, completely hypothetically, that we are not a big fan of Stata or simply want to learn the mechanics behind an ordered probit model by coding it up ourselves. \n",
    "\n",
    "The resulting function should be user-friendly and its usage should look approximately like this:\n",
    "\n",
    "``` python\n",
    "data = pd.read_pickle(\"ologit.pickle\")\n",
    "formula = 'apply ~ pared + public + gpa'\n",
    "estimates = ordered_logit(formula, data)\n",
    "\n",
    "```\n",
    "The example is taken from the [Stata Documentation](https://stats.idre.ucla.edu/stata/dae/ordered-logistic-regression/). The correct parameters for this model are ``[1.047664, -.0586828, .6157458, 2.203323,  4.298767]``\n",
    "\n",
    "In this notebook we show you how estimagic can help you to implement such a model very easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from patsy import dmatrices\n",
    "from estimagic.optimization.optimize import maximize\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the user input\n",
    "\n",
    "First we have to take the formula and dataset, extract all relevant information about the model and construct the inputs for the likelihood function. \n",
    "\n",
    "We will need four inputs:\n",
    "\n",
    "1. A DataFrame with start parameters for the optimization.\n",
    "2. An array with the dependent variable.\n",
    "3. A 2d array with explanatory variables.\n",
    "4. Constraints for the optimization that keep the cutoffs increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit_processing(formula, data):\n",
    "    \"\"\"Process user input for an ordered logit model.\"\"\"\n",
    "    # extract data arrays\n",
    "    y, x = dmatrices(formula + ' - 1', data, return_type='dataframe')\n",
    "    y = y[y.columns[0]]\n",
    "    \n",
    "    # extract dimensions\n",
    "    num_choices = len(y.unique())\n",
    "    beta_names = list(x.columns)\n",
    "    num_betas = len(beta_names)\n",
    "    num_cutoffs = num_choices - 1\n",
    "    \n",
    "    # set-up index for params_df\n",
    "    names = beta_names + list(range(num_cutoffs))\n",
    "    categories = ['beta'] * num_betas + ['cutoff'] * num_cutoffs\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        zip(categories, names), names=['type', 'name'])\n",
    "    \n",
    "    # make params_df\n",
    "    np.random.seed(5471)\n",
    "    start_params = pd.DataFrame(index=index)\n",
    "    start_params['value'] = np.hstack(\n",
    "        [np.random.uniform(low=-0.5, high=0.5, size=len(x.columns)),\n",
    "        np.arange(num_cutoffs) * 2])\n",
    "    start_params[\"group\"] = start_params.index.get_level_values(\"type\")\n",
    "    \n",
    "    # make constraints\n",
    "    constr = [{'loc': 'cutoff', 'type': 'increasing'}]\n",
    "    \n",
    "    return start_params, y.to_numpy().astype(int), x.to_numpy(), constr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have never programmed an estimator before, you migt be surprised how much code is spent on processing compared to calculating the actual likelihood function. This will almost always be the case, at least if you try to make your estimator flexible and user friendly. Estimagic is there to shorten this type of code as much as possible. \n",
    "\n",
    "### Calculate the Likelihood\n",
    "\n",
    "Next we have to evaluate the likelihood function, given parameters and data. There are more efficient ways of calculating the likelihood for an ordered logit, but this one was chosen for brevity and readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit_loglike(params, y, x):\n",
    "    \"\"\"Likelihood function of an orderd logit model.\"\"\"\n",
    "    # parse the parameter vector into its quantities\n",
    "    beta = params.loc[\"beta\", \"value\"].to_numpy()\n",
    "    cutoffs = params.loc[\"cutoff\", \"value\"].to_numpy()\n",
    "    \n",
    "    # calculate deterministic part of utilities\n",
    "    xb = x.dot(beta)\n",
    "    \n",
    "    # evaluate likelihood\n",
    "    upper_cutoffs = np.hstack([cutoffs, np.inf])[y]\n",
    "    lower_cutoffs = np.hstack([-np.inf, cutoffs])[y]\n",
    "    upper_cdf = stats.logistic.cdf(upper_cutoffs - xb)\n",
    "    lower_cdf = stats.logistic.cdf(lower_cutoffs - xb)\n",
    "    \n",
    "    return np.log(upper_cdf - lower_cdf).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ordered_logit command\n",
    "\n",
    "Finally we have to maximize the likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit(formula, data, dashboard=False):\n",
    "    \"\"\"Estimate an ordered probit model with maximum likelihood.\n",
    "    \n",
    "    Args:\n",
    "        formula (str): A patsy formula\n",
    "        data (str): A pandas DataFrame\n",
    "        dashboard (bool): Switch on the dashboard.\n",
    "        \n",
    "    Returns:\n",
    "        res: optimization result.\n",
    "        \n",
    "    \"\"\"\n",
    "    params, y, x, constr = ordered_logit_processing(formula, data)\n",
    "    \n",
    "    res = maximize(\n",
    "        criterion=ordered_logit_loglike, \n",
    "        params=params, \n",
    "        algorithm='scipy_L-BFGS-B',\n",
    "        constraints=constr,\n",
    "        criterion_kwargs={\"y\": y, \"x\": x}, \n",
    "        dashboard=dashboard)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that estimagic has a `maximize` function, so you don't have to switch the sign of your objective function to do a maximization!\n",
    "\n",
    "### Use the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"ologit.pickle\")\n",
    "form = \"apply ~ pared + public + gpa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bokeh app running at: http://localhost:46987/\n"
     ]
    }
   ],
   "source": [
    "info, params = ordered_logit(form, df, dashboard=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">beta</th>\n",
       "      <th>pared</th>\n",
       "      <td>1.047661</td>\n",
       "      <td>1.047664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>-0.058685</td>\n",
       "      <td>-0.058683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.615745</td>\n",
       "      <td>0.615746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cutoff</th>\n",
       "      <th>0</th>\n",
       "      <td>2.203319</td>\n",
       "      <td>2.203323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.298763</td>\n",
       "      <td>4.298767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  value   correct\n",
       "type   name                      \n",
       "beta   pared   1.047661  1.047664\n",
       "       public -0.058685 -0.058683\n",
       "       gpa     0.615745  0.615746\n",
       "cutoff 0       2.203319  2.203323\n",
       "       1       4.298763  4.298767"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"correct\"] = [1.047664, -.0586828, .6157458, 2.203323,  4.298767]\n",
    "params[[\"value\", \"correct\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good! I actually had to try three optimizers to get at least one differenet digit which makes the result more credible. Other optimizers like `nlopt_bobyqa` and `nlopt_neledermead` hit it on all digits!\n",
    "\n",
    "Of course this model is way too simple to actually see all the benefits of estimagic. But we wanted to keep it simple. And the very nice way of parsing the parameters expressing the constraint that cutoffs have to be increasing hints at estimagic's usefulness in models with hundred or more parameters with plenty of constraints!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
