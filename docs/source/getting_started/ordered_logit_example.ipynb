{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordered Logit Example\n",
    "\n",
    "Let's suppose, completely hypothetically, that we are not a big fan of Stata or simply want to learn the mechanics behind an ordered logit model by coding it up ourselves. \n",
    "\n",
    "In this notebook we show you how estimagic can help you to implement such a model very easily. Implementing a logit model consists of four basic steps:\n",
    "\n",
    "1. Processing the user input into inputs for the likelihood function\n",
    "2. Writing the likelihood function of an ordered logit model\n",
    "3. Maximizing the likelihood function\n",
    "4. Calculating standard errors\n",
    "\n",
    "The first two have to be done by the user, the last two are done by estimagic. \n",
    "\n",
    "To be very clear: Estimagic is not a package to estimate logit models or other models that are implemented in Stata, statsmodels or anywhere else. It's purpose is to estimate parameters with custom likelihood or method of simulated moments functions. We just use an orederd logit model as example of a very simple likelihood function. \n",
    "\n",
    "The example we will use to test our model is taken from the [Stata Documentation](https://stats.idre.ucla.edu/stata/dae/ordered-logistic-regression/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from patsy import dmatrices\n",
    "from estimagic import maximize\n",
    "from estimagic.inference.likelihood_inference import do_likelihood_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the user input\n",
    "\n",
    "First we have to take the formula and dataset, extract all relevant information about the model and construct the inputs for the likelihood function. \n",
    "\n",
    "We will need four inputs:\n",
    "\n",
    "1. A DataFrame with start parameters for the optimization.\n",
    "2. An array with the dependent variable.\n",
    "3. A 2d array with explanatory variables.\n",
    "4. Constraints for the optimization that keep the cutoffs increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit_processing(formula, data):\n",
    "    \"\"\"Process user input for an ordered logit model.\"\"\"\n",
    "    # extract data arrays\n",
    "    y, x = dmatrices(formula + ' - 1', data, return_type='dataframe')\n",
    "    y = y[y.columns[0]]\n",
    "    \n",
    "    # extract dimensions\n",
    "    num_choices = len(y.unique())\n",
    "    beta_names = list(x.columns)\n",
    "    num_betas = len(beta_names)\n",
    "    num_cutoffs = num_choices - 1\n",
    "    \n",
    "    # set-up index for params_df\n",
    "    names = beta_names + list(range(num_cutoffs))\n",
    "    categories = ['beta'] * num_betas + ['cutoff'] * num_cutoffs\n",
    "    index = pd.MultiIndex.from_tuples(\n",
    "        zip(categories, names), names=['type', 'name'])\n",
    "    \n",
    "    # make params_df\n",
    "    np.random.seed(5471)\n",
    "    start_params = pd.DataFrame(index=index)\n",
    "    start_params['value'] = np.hstack(\n",
    "        [np.random.uniform(low=-0.5, high=0.5, size=len(x.columns)),\n",
    "        np.arange(num_cutoffs) * 2])\n",
    "    start_params[\"group\"] = start_params.index.get_level_values(\"type\")\n",
    "    \n",
    "    # make constraints\n",
    "    constr = [{'loc': 'cutoff', 'type': 'increasing'}]\n",
    "    \n",
    "    # turn pandas objects into numpy arrays\n",
    "    y_arr = y.to_numpy().astype(int)\n",
    "    x_arr = x.to_numpy()\n",
    "    \n",
    "    return start_params, y_arr, x_arr, constr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Likelihood\n",
    "\n",
    "Next, we want to evaluate the likelihood function, given parameters and data. There are more efficient ways of calculating the likelihood for an ordered logit but this one was chosen for brevity and readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_logit_loglike(params, y, x):\n",
    "    \"\"\"Likelihood function of an orderd logit model.\"\"\"\n",
    "    # parse the parameter vector into its quantities\n",
    "    beta = params.loc[\"beta\", \"value\"].to_numpy()\n",
    "    cutoffs = params.loc[\"cutoff\", \"value\"].to_numpy()\n",
    "    \n",
    "    # calculate deterministic part of utilities\n",
    "    xb = x.dot(beta)\n",
    "    \n",
    "    # evaluate likelihood\n",
    "    upper_cutoffs = np.hstack([cutoffs, np.inf])[y]\n",
    "    lower_cutoffs = np.hstack([-np.inf, cutoffs])[y]\n",
    "    upper_cdf = stats.logistic.cdf(upper_cutoffs - xb)\n",
    "    lower_cdf = stats.logistic.cdf(lower_cutoffs - xb)\n",
    "    \n",
    "    contributions = np.log(upper_cdf - lower_cdf)\n",
    "    \n",
    "    res = {\n",
    "        \"contributions\": contributions,\n",
    "        \"value\": contributions.sum()\n",
    "    }\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have never programmed an estimator before, you migt be surprised how much code is spent on processing compared to calculating the actual likelihood function. This will almost always be the case - \n",
    "at least if you try to make your estimator flexible and user friendly. Estimagic is there to shorten this type of code as much as possible. \n",
    "\n",
    "Another peculiarity you might notice is that the likelihood function does not just return a scalar value, but also the likelihood contributions of each individual. This is because some optimizers (e.g. bhhh) can actually use the information on the contributions. Morover, you will need the contributions to calculate standard errors by the outer product of gradients. \n",
    "\n",
    "All estimagic functions (whether for numerical differentiation, standard error calculation or optimization) will simply pick from the dictionary what they need!\n",
    "\n",
    "\n",
    "### Maximizing the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"ologit.pickle\")\n",
    "formula = \"apply ~ pared + public + gpa\"\n",
    "start_params, y, x, constraints = ordered_logit_processing(formula, data)\n",
    "    \n",
    "res = maximize(\n",
    "    criterion=ordered_logit_loglike, \n",
    "    params=start_params, \n",
    "    algorithm='scipy_lbfgsb',\n",
    "    constraints=constraints,\n",
    "    criterion_kwargs={\"y\": y, \"x\": x}, \n",
    "    logging=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>value</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">beta</th>\n",
       "      <th>pared</th>\n",
       "      <td>beta</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.047661</td>\n",
       "      <td>beta_pared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>beta</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.058685</td>\n",
       "      <td>beta_public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>beta</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.615744</td>\n",
       "      <td>beta_gpa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cutoff</th>\n",
       "      <th>0</th>\n",
       "      <td>cutoff</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.203318</td>\n",
       "      <td>cutoff_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cutoff</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>4.298762</td>\n",
       "      <td>cutoff_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                group  lower_bound  upper_bound     value         name\n",
       "type   name                                                           \n",
       "beta   pared     beta         -inf          inf  1.047661   beta_pared\n",
       "       public    beta         -inf          inf -0.058685  beta_public\n",
       "       gpa       beta         -inf          inf  0.615744     beta_gpa\n",
       "cutoff 0       cutoff         -inf          inf  2.203318     cutoff_0\n",
       "       1       cutoff         -inf          inf  4.298762     cutoff_1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = res[\"solution_params\"]\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.ordered_logit_loglike(params, y, x)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estimagic.decorators import numpy_interface\n",
    "numpy_interface(ordered_logit_loglike, params=params, constraints=constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>p_value</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">beta</th>\n",
       "      <th>pared</th>\n",
       "      <td>1.048</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.507</td>\n",
       "      <td>1.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public</th>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.811</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>0.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.616</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.077</td>\n",
       "      <td>1.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cutoff</th>\n",
       "      <th>0</th>\n",
       "      <td>2.203</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.592</td>\n",
       "      <td>3.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.299</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.641</td>\n",
       "      <td>5.956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               value  standard_error  p_value  ci_lower  ci_upper\n",
       "type   name                                                      \n",
       "beta   pared   1.048           0.276    0.000     0.507     1.589\n",
       "       public -0.059           0.269    0.811    -0.587     0.469\n",
       "       gpa     0.616           0.275    0.025     0.077     1.155\n",
       "cutoff 0       2.203           0.822    0.007     0.592     3.815\n",
       "       1       4.299           0.846    0.000     2.641     5.956"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference, free_cov = do_likelihood_inference(\n",
    "    loglike=ordered_logit_loglike,\n",
    "    params=params,\n",
    "    loglike_kwargs={\"x\": x, \"y\": y},\n",
    "    n_samples=10_000,\n",
    "    constraints=constraints,\n",
    ")\n",
    "\n",
    "inference.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to STATA's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>stata_value</th>\n",
       "      <th>stata_standard_error</th>\n",
       "      <th>stata_p_value</th>\n",
       "      <th>stata_ci_lower</th>\n",
       "      <th>stata_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pared</td>\n",
       "      <td>1.048</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.527</td>\n",
       "      <td>1.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>public</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.844</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpa</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.105</td>\n",
       "      <td>1.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cut1</td>\n",
       "      <td>2.203</td>\n",
       "      <td>0.780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675</td>\n",
       "      <td>3.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cut2</td>\n",
       "      <td>4.299</td>\n",
       "      <td>0.804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.722</td>\n",
       "      <td>5.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  stata_value  stata_standard_error  stata_p_value  stata_ci_lower  \\\n",
       "0   pared        1.048                 0.266          0.000           0.527   \n",
       "1  public       -0.059                 0.298          0.844          -0.642   \n",
       "2     gpa        0.616                 0.261          0.018           0.105   \n",
       "3    cut1        2.203                 0.780            NaN           0.675   \n",
       "4    cut2        4.299                 0.804            NaN           2.722   \n",
       "\n",
       "   stata_ci_upper  \n",
       "0           1.569  \n",
       "1           0.525  \n",
       "2           1.127  \n",
       "3           3.731  \n",
       "4           5.875  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stata_results = pd.read_csv(\"stata_ologit_results.csv\")\n",
    "stata_results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good! The parameter estimates line up perfectly. I actually had to try three optimizers to get at least one differenet digit which makes the result more credible. Other optimizers like `nlopt_bobyqa` and `nlopt_neledermead` hit it on all digits!\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "Note that standard error calculation, especially in combination with constraints is still considered experimental in estimagic.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the dashboard for monitoring the optimization\n",
    "\n",
    "Often you may want to monitor an optimization to see how far the algorithm has moved away from the start values or see how the \n",
    "algorithm arrived at its solution after it has finished.\n",
    "\n",
    "\n",
    "Both can be done using the estimagic dashboard.\n",
    "\n",
    "To use the dashboard, we need to activate logging \n",
    "which we had deactivated up until now.\n",
    "To activate logging, simply supply a database path to \n",
    "`ordered_logit`.\n",
    "\n",
    "To start the dashboard, make sure you have the estimagic environment\n",
    "installed and activated.\n",
    "\n",
    "Then all you need to do is navigate to the path's directory in your \n",
    "command line, start the cell below and enter the following into\n",
    "your command line after the optimization has started:\n",
    "\n",
    "``estimagic dashboard {db_path}`` \n",
    "\n",
    "This should open a page in your browser where you can press \n",
    "\"Start Updating from Database\" to start watching the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = './logging.db'\n",
    "\n",
    "res = maximize(\n",
    "    criterion=ordered_logit_loglike, \n",
    "    params=start_params, \n",
    "    algorithm='scipy_lbfgsb',\n",
    "    constraints=constraints,\n",
    "    criterion_kwargs={\"y\": y, \"x\": x}, \n",
    "    logging=db_path,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
